{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continent-logistics",
   "metadata": {},
   "source": [
    "## 1. Extract the birth date of the patients from the patient_dimension.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-farming",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df_patient_dimension = pd.read_csv(\"/data/datasets/Tianchen/data_from_old_server/2021/ADRD_data_from_Xi/i2b2/patient_dimension.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_patient_dimension.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-treasure",
   "metadata": {},
   "source": [
    "## 2. Calculate the age of the patients at each encounter with the START_DATE under DIAGNOSIS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIAGNOSES = pd.read_csv(\"/data/datasets/Tianchen/data_from_old_server/2021/ADRD_data_from_Xi/process_observation/process_observation/DIAGNOSES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tropical-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(DIAGNOSES.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-attack",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Merge dataframes on 'pid' to get birth_date for each encounter\n",
    "# merged_df = pd.merge(DIAGNOSES, df_patient_dimension[['deid_pat_ID', 'BIRTH_DATE']], on='deid_pat_ID')\n",
    "merged_df['START_DATE'] = pd.to_datetime(merged_df['START_DATE'])\n",
    "merged_df['BIRTH_DATE'] = pd.to_datetime(merged_df['BIRTH_DATE'])\n",
    "merged_df['age_at_encounter'] = (merged_df['START_DATE'] - merged_df['BIRTH_DATE']).dt.days // 365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merged_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indonesian-frank",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['deid_pat_ID', 'deid_enc_ID',\"CONCEPT_CD\",'age_at_encounter']\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "merge_df_selected = merged_df[selected_columns]\n",
    "\n",
    "\n",
    "# Sort within each patient group by 'age_at_encounter'\n",
    "merge_df_selected_sorted = merge_df_selected.sort_values(by=['deid_pat_ID', 'age_at_encounter'])\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "# print(merge_df_selected_sorted.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-entrepreneur",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(merge_df_selected_sorted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-matter",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove duplicate encounters\n",
    "merge_df_age = merge_df_selected_sorted.drop_duplicates(subset=['deid_pat_ID', 'deid_enc_ID'])\n",
    "print(merge_df_age.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increased-shelf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get age_vector for each patient\n",
    "\n",
    "# Group by 'pid' and aggregate 'age_at_encounter' into a list\n",
    "patient_age_df = merge_df_age.groupby('deid_pat_ID')['age_at_encounter'].agg(list).reset_index()\n",
    "\n",
    "# Rename the column to 'age_vector'\n",
    "patient_age_df = patient_age_df.rename(columns={'age_at_encounter': 'age_vector'})\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(patient_age_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "strange-registration",
   "metadata": {},
   "source": [
    "## 3. Aggregate the diagnosis codes of the patients under the same encounter defined by deid_enc_ID under DIAGNOSIS.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "musical-germany",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['deid_pat_ID', 'deid_enc_ID',\"CONCEPT_CD\",'age_at_encounter']\n",
    "# Initialize an empty dictionary to store aggregated vectors\n",
    "pid_diagnosis_dict = {}\n",
    "# Iterate through each row of the DataFrame\n",
    "for index, row in merge_df_selected_sorted.iterrows():\n",
    "    pid = row['deid_pat_ID']\n",
    "    encounter_id = row['deid_enc_ID']\n",
    "    code = row['CONCEPT_CD']\n",
    "\n",
    "    # Check if the pid is already in the dictionary\n",
    "    if pid in pid_diagnosis_dict:\n",
    "        # Check if encounter_id is already in the dictionary\n",
    "        if encounter_id in pid_diagnosis_dict[pid]:\n",
    "            # Append the diagnosis code to the existing encounter_id vector\n",
    "            pid_diagnosis_dict[pid][encounter_id].append(code)\n",
    "        else:\n",
    "            # Initialize a new encounter_id vector if encounter_id is not in the dictionary\n",
    "            pid_diagnosis_dict[pid][encounter_id] = ['CLS', code, 'SEP']\n",
    "    else:\n",
    "        # Initialize a new dictionary entry for pid and encounter_id\n",
    "        pid_diagnosis_dict[pid] = {encounter_id: ['CLS', code, 'SEP']}\n",
    "        \n",
    "# Initialize an empty list to store the final rows of the new DataFrame\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through the dictionary to create rows for the new DataFrame\n",
    "for pid, encounters in pid_diagnosis_dict.items():\n",
    "    # Concatenate the vectors for each encounter_id\n",
    "    for encounter_id, codes in encounters.items():\n",
    "        # Create a new row with pid, encounter_id, and the aggregated code vector\n",
    "        new_row = {'pid': pid, 'code': codes}\n",
    "        new_rows.append(new_row)\n",
    "# Create the new DataFrame\n",
    "patient_code_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(patient_code_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(patient_code_df.columns)\n",
    "column_mapping = {\n",
    "    'pid': 'deid_pat_ID',\n",
    "    'code': 'diagnosis_code'\n",
    "}\n",
    "\n",
    "patient_code_df = patient_code_df.rename(columns=column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-usage",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df = pd.merge(merge_df_age, patient_code_df, on='deid_pat_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.to_csv(\"/data/datasets/leyang/merged_age_diagnosis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "involved-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(final_merged_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-anderson",
   "metadata": {},
   "source": [
    "\n",
    "You will need to remove code that is not ICD.\n",
    "You will need to combine the diagnosis codes from the same encounter identified by deid_enc_ID.\n",
    "Each of the row will contain all the encounters from a single patient.\n",
    "The ‘SEP’ is used to separate diagnosis codes from different encounters instead of codes within the same encounter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boolean-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check how many encounters appear >= twice, for patient p, encounter j: the number of diagnosis is m_j_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-generic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since each encounter_id may have one or multiple diagnosis_code,  for each encounter_id, denote the corresponding diagnosis_code {d_1, d_2, ..,d_{m_j_p}}  and  create a vector v_{j_p}={d_1, d_2, ..,d_{m_j_p}}\n",
    "# since each pid has multiple encounter_id, for each pid, Aggregate all the diagnosis code vector v_{j_p} under the encounterids, and seperate each v_{j_p} with \"SEP\". Also, You will need to place 'CLS' at the begin of the vector and an 'SEP' at the end of the vector. \n",
    "# For example, if a pid has two encounter_id, and for the first encounter_id there are 2 dignosis: {d_1 = 3, d_2 = 5}, for the second encounter_id there are 3 diagnosis: {d_1 = 1, d_2 = 4, d_3 = 5}. Then the aggregated vector for this pid is {CLS,3,5,SEP,1,4,5,SEP}\n",
    "# create a new dataframe with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-paper",
   "metadata": {},
   "outputs": [],
   "source": [
    "   pid              code\n",
    "0    1  [CLS, 1,2, SEP, 3, SEP]\n",
    "1    2    [CLS, 4, SEP, 5, SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "devoted-daily",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid                      code\n",
      "0    1  [CLS, 1, 2, SEP, 3, SEP]\n",
      "1    2     [CLS, 4, SEP, 5, SEP]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'pid': [1, 1, 1, 2, 2],\n",
    "        'encounter_id': [101, 101, 102, 201, 202],\n",
    "        'diagnosis_code': ['1', '2', '3', '4', '5']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize an empty dictionary to store aggregated vectors\n",
    "pid_diagnosis_dict = {}\n",
    "\n",
    "# Iterate through each row of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    pid = row['pid']\n",
    "    encounter_id = row['encounter_id']\n",
    "    code = row['diagnosis_code']\n",
    "\n",
    "    # Check if the pid is already in the dictionary\n",
    "    if pid in pid_diagnosis_dict:\n",
    "        # Check if encounter_id is already in the dictionary\n",
    "        if encounter_id in pid_diagnosis_dict[pid]:\n",
    "            # Append the diagnosis code to the existing encounter_id vector\n",
    "            pid_diagnosis_dict[pid][encounter_id].append(code)\n",
    "        else:\n",
    "            # Initialize a new encounter_id vector if encounter_id is not in the dictionary\n",
    "            pid_diagnosis_dict[pid][encounter_id] = [code]\n",
    "    else:\n",
    "        # Initialize a new dictionary entry for pid and encounter_id\n",
    "        pid_diagnosis_dict[pid] = {encounter_id: [code]}\n",
    "\n",
    "# Initialize an empty list to store the final rows of the new DataFrame\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through the dictionary to create rows for the new DataFrame\n",
    "for pid, encounters in pid_diagnosis_dict.items():\n",
    "    # Concatenate the vectors for each encounter_id\n",
    "    concatenated_codes = []\n",
    "    for encounter_id, codes in encounters.items():\n",
    "        concatenated_codes += codes + ['SEP']\n",
    "\n",
    "    # Create a new row with pid, encounter_id, and the aggregated code vector\n",
    "    new_row = {'pid': pid, 'code': ['CLS'] + concatenated_codes}\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Create the new DataFrame\n",
    "patient_code_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(patient_code_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "australian-pointer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-leyang.sun",
   "language": "python",
   "name": "leyang.sun-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
