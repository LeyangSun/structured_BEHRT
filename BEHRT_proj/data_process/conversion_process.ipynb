{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "removed-uruguay",
   "metadata": {},
   "source": [
    "## 0. Get the code map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "underlying-superior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "grand-reset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ICD9                                   Phenotypes\n",
      "0    8.00                         Intestinal infection\n",
      "1    8.50                          Bacterial enteritis\n",
      "2    8.51                            Intestinal e.coli\n",
      "3    8.52     Intestinal infection due to C. difficile\n",
      "4    8.60                              Viral Enteritis\n",
      "5    8.70         Intestinal infection due to protozoa\n",
      "6   10.00                                 Tuberculosis\n",
      "7   31.00           Diseases due to other mycobacteria\n",
      "8   31.10                                      Leprosy\n",
      "9   38.00                                   Septicemia\n",
      "10  38.10                     Gram negative septicemia\n",
      "11  38.20                     Gram positive septicemia\n",
      "12  38.30                                   Bacteremia\n",
      "13  41.00                      Bacterial infection NOS\n",
      "14  41.10                    Staphylococcus infections\n",
      "15  41.11  Methicillin sensitive Staphylococcus aureus\n",
      "16  41.12  Methicillin resistant Staphylococcus aureus\n",
      "17  41.20                      Streptococcus infection\n",
      "18  41.21                     Rheumatic fever / chorea\n",
      "19  41.40                                      E. coli\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "icd9_data = pd.read_csv(\"/home/leyang.sun/BERHT/phecode1.csv\")\n",
    "icd10_data = pd.read_csv(\"/home/leyang.sun/BERHT/phecode2.csv\")\n",
    "icd9_df = icd9_data[[\"phecode\", \"phenotype\"]]\n",
    "new_Col = [\"ICD9\", \"Phenotypes\" ]\n",
    "icd9_df.columns  = new_Col\n",
    "print(icd9_df.head(20))\n",
    "print(icd9_df[\"ICD9\"].dtype) # need to convert to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "independent-accordance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ICD9  ICD10            Phenotypes\n",
      "0    8.0    A00  Intestinal infection\n",
      "1    8.0  A00.0  Intestinal infection\n",
      "2    8.0  A00.1  Intestinal infection\n",
      "3    8.0  A00.9  Intestinal infection\n",
      "4    8.0    A01  Intestinal infection\n",
      "5    8.5  A01.0  Intestinal infection\n",
      "6    8.0  A01.1  Intestinal infection\n",
      "7    8.0  A01.2  Intestinal infection\n",
      "8    8.0  A01.3  Intestinal infection\n",
      "9    8.0  A01.4  Intestinal infection\n",
      "10   8.5    A02  Intestinal infection\n",
      "11   8.5  A02.0  Intestinal infection\n",
      "12  38.1  A02.1   bacterial infection\n",
      "13   8.5  A02.2  Intestinal infection\n",
      "14   8.5  A02.8  Intestinal infection\n",
      "15   8.5  A02.9  Intestinal infection\n",
      "16   8.5    A03  Intestinal infection\n",
      "17   8.5  A03.0  Intestinal infection\n",
      "18   8.5  A03.1  Intestinal infection\n",
      "19   8.5  A03.2  Intestinal infection\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "icd10_df = icd10_data[[\"PHECODE\", 'ICD10', 'Excl. Phenotypes']]\n",
    "new_Col = [\"ICD9\", \"ICD10\", \"Phenotypes\" ]\n",
    "icd10_df.columns  = new_Col\n",
    "print(icd10_df.head(20))\n",
    "print(icd10_df[\"ICD9\"].dtype) # object, need to convert both to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clinical-intermediate",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(icd9_df, icd10_df, on='Phenotypes',how='outer')\n",
    "df_merged = df_merged.astype({'ICD9_x':'string', 'ICD9_y':'string', 'ICD10':'string'})\n",
    "df_merged = df_merged.fillna(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sitting-savannah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ICD9_x            Phenotypes ICD9_y  ICD10\n",
      "0    8.0  Intestinal infection    8.0    A00\n",
      "1    8.0  Intestinal infection    8.0  A00.0\n",
      "2    8.0  Intestinal infection    8.0  A00.1\n",
      "3    8.0  Intestinal infection    8.0  A00.9\n",
      "4    8.0  Intestinal infection    8.0    A01\n"
     ]
    }
   ],
   "source": [
    "print(df_merged.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "surrounded-magnet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping dictionary\n",
    "mapping_dict = {}\n",
    "mapped_number = 0\n",
    "for index, row in df_merged.iterrows():\n",
    "    \n",
    "    disease = row['Phenotypes']\n",
    "    icd9_1 = row['ICD9_x']\n",
    "    icd9_2 = row['ICD9_y']\n",
    "    icd10 = row['ICD10']\n",
    "\n",
    "   \n",
    "    if disease in mapping_dict.keys():\n",
    "        disease_code = mapping_dict[disease]\n",
    "        \n",
    "        if icd9_1 not in disease_code['ICD9_1']:\n",
    "            disease_code['ICD9_1'].append(icd9_1)\n",
    "        \n",
    "        if icd9_2 not in disease_code['ICD9_2']:\n",
    "            disease_code['ICD9_2'].append(icd9_2)\n",
    "            \n",
    "        if icd10 not in disease_code['ICD10']:\n",
    "            disease_code['ICD10'].append(icd10)\n",
    "       \n",
    "   \n",
    "    else:\n",
    "        mapped_number += 1\n",
    "        mapping_dict[disease] = {\n",
    "            'ICD9_1': [icd9_1],\n",
    "            'ICD9_2': [icd9_2],\n",
    "            'ICD10': [icd10],\n",
    "            'MappedNumber': mapped_number\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continent-disco",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mapped number for the code '41.12' is 17\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage: Given an ICD9 or ICD10 code, identify the mapped number\n",
    "code_to_find = '41.12'  # Replace with the code you want to search for, should be string\n",
    "\n",
    "mapped_number = None\n",
    "for disease, mapping in mapping_dict.items():\n",
    "    if code_to_find in mapping['ICD9_1']  or code_to_find in mapping['ICD9_2'] or code_to_find in mapping['ICD10'] :\n",
    "        mapped_number = mapping['MappedNumber']\n",
    "        break\n",
    "    \n",
    "\n",
    "if mapped_number is not None:\n",
    "    print(f\"The mapped number for the code '{code_to_find}' is {mapped_number}\")\n",
    "else:\n",
    "    print(f\"Code '{code_to_find}' not found in the mapping.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "numeric-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the dictionary into binary mode\n",
    "file_path = 'mapping_dict.pkl'\n",
    "with open(file_path, 'wb') as file:\n",
    "    pickle.dump(mapping_dict, file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "executed-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file in binary read mode\n",
    "with open(file_path, 'rb') as file:\n",
    "    mapping_dict = pickle.load(file)\n",
    "# Close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "looking-arbor",
   "metadata": {},
   "source": [
    "## 1. Extract the birth date of the patients from the patient_dimension.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contained-module",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "df_patient_dimension = pd.read_csv(\"/data/datasets/Tianchen/data_from_old_server/2021/ADRD_data_from_Xi/i2b2/patient_dimension.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "electoral-anderson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                   deid_pat_ID VITAL_STATUS_CD  BIRTH_DATE  DEATH_DATE  SEX_CD  \\\n",
      "0        IRB202001139_PAT_989               N  1931-11-13         NaN    Male   \n",
      "1        IRB202001139_PAT_730               N  1924-06-24         NaN  Female   \n",
      "2        IRB202001139_PAT_269               Y  1933-04-20  2018-12-03  Female   \n",
      "3        IRB202001139_PAT_737               N  1971-02-10         NaN  Female   \n",
      "4        IRB202001139_PAT_679               N  1964-12-27         NaN  Female   \n",
      "...                       ...             ...         ...         ...     ...   \n",
      "52189  IRB202001139_PAT_49128               N  1980-03-02         NaN  Female   \n",
      "52190  IRB202001139_PAT_49106               N  2003-01-16         NaN    Male   \n",
      "52191  IRB202001139_PAT_49180               N  1931-03-06         NaN  Female   \n",
      "52192  IRB202001139_PAT_49240               N  2000-09-25         NaN  Female   \n",
      "52193  IRB202001139_PAT_49255               N  1968-01-26         NaN  Female   \n",
      "\n",
      "       AGE_IN_YEARS_NUM LANGUAGE_CD                    RACE_CD  \\\n",
      "0                    88     English                      White   \n",
      "1                    95     English                      Other   \n",
      "2                    87     English                      White   \n",
      "3                    49     English                      White   \n",
      "4                    55     English                      White   \n",
      "...                 ...         ...                        ...   \n",
      "52189                40     English                      White   \n",
      "52190                17     English                      Other   \n",
      "52191                89     English                      White   \n",
      "52192                19     English                      White   \n",
      "52193                52     English  Black or African American   \n",
      "\n",
      "      MARITAL_STATUS_CD  RELIGION_CD     ZIP_CD  STATECITYZIP_PATH  INCOME_CD  \\\n",
      "0                Single          NaN  321-Other                NaN        NaN   \n",
      "1               Married          NaN      32606                NaN        NaN   \n",
      "2                Single          NaN  321-Other                NaN        NaN   \n",
      "3               Married          NaN      33830                NaN        NaN   \n",
      "4              Divorced          NaN      32607                NaN        NaN   \n",
      "...                 ...          ...        ...                ...        ...   \n",
      "52189           Married          NaN  320-Other                NaN        NaN   \n",
      "52190            Single          NaN        315                NaN        NaN   \n",
      "52191           Married          NaN      32034                NaN        NaN   \n",
      "52192            Single          NaN      32571                NaN        NaN   \n",
      "52193             Other          NaN      32208                NaN        NaN   \n",
      "\n",
      "                    ETHNIC_CD      PAYER_CD               SMOKING_STATUS_CD  \\\n",
      "0      Not Hispanic or Latino      SELF PAY                             NaN   \n",
      "1      Not Hispanic or Latino      Medicare                  Never Assessed   \n",
      "2      Not Hispanic or Latino  Medicare HMO                   Former Smoker   \n",
      "3      Not Hispanic or Latino       Federal                   Never Smoker    \n",
      "4      Not Hispanic or Latino  Medicare HMO                   Never Smoker    \n",
      "...                       ...           ...                             ...   \n",
      "52189  Not Hispanic or Latino       Federal                   Never Smoker    \n",
      "52190      Hispanic or Latino  Medicaid HMO  Smoker, Current Status Unknown   \n",
      "52191  Not Hispanic or Latino      Medicare                   Former Smoker   \n",
      "52192  Not Hispanic or Latino  Medicaid HMO                   Never Smoker    \n",
      "52193  Not Hispanic or Latino   Jax Charity                  Never Assessed   \n",
      "\n",
      "         COUNTY_CD SSN_VITAL_STATUS_CD MYCHART_CD CANCER_IND  \n",
      "0           MARION                   N          N          N  \n",
      "1          ALACHUA                   N          N          N  \n",
      "2           PUTNAM                   N          N          N  \n",
      "3             POLK                   N          N          N  \n",
      "4          ALACHUA                   N          Y          Y  \n",
      "...            ...                 ...        ...        ...  \n",
      "52189       NASSAU                   N          N          N  \n",
      "52190  Non-Florida                   N          N          N  \n",
      "52191       NASSAU                   N          Y          Y  \n",
      "52192   SANTA ROSA                   N          N          N  \n",
      "52193        DUVAL                   N          N          N  \n",
      "\n",
      "[52194 rows x 20 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_patient_dimension.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-dinner",
   "metadata": {},
   "source": [
    "## 2. Calculate the age of the patients at each encounter with the START_DATE under DIAGNOSIS.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-madonna",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "confirmed-deadline",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39858/1002630756.py:1: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  DIAGNOSES = pd.read_csv(\"/data/datasets/Tianchen/data_from_old_server/2021/ADRD_data_from_Xi/process_observation/process_observation/DIAGNOSES.csv\")\n"
     ]
    }
   ],
   "source": [
    "DIAGNOSES = pd.read_csv(\"/data/datasets/Tianchen/data_from_old_server/2021/ADRD_data_from_Xi/process_observation/process_observation/DIAGNOSES.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "exact-language",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      deid_pat_ID               deid_enc_ID     CONCEPT_CD  \\\n",
      "0           IRB202001139_PAT_626    IRB202001139_ENC_42808  COMOR:ALCOHOL   \n",
      "1           IRB202001139_PAT_862    IRB202001139_ENC_33331  COMOR:ALCOHOL   \n",
      "2            IRB202001139_PAT_27    IRB202001139_ENC_40434  COMOR:ALCOHOL   \n",
      "3           IRB202001139_PAT_165    IRB202001139_ENC_33614  COMOR:ALCOHOL   \n",
      "4           IRB202001139_PAT_333     IRB202001139_ENC_3261  COMOR:ALCOHOL   \n",
      "...                          ...                       ...            ...   \n",
      "44714088  IRB202001139_PAT_49258  IRB202001139_ENC_3630261  ICD9-D:366.10   \n",
      "44714089  IRB202001139_PAT_49258  IRB202001139_ENC_3630333  ICD9-D:338.29   \n",
      "44714090  IRB202001139_PAT_49258  IRB202001139_ENC_3630284  ICD9-D:278.01   \n",
      "44714091  IRB202001139_PAT_49258  IRB202001139_ENC_3630154  ICD9-D:278.00   \n",
      "44714092  IRB202001139_PAT_49258  IRB202001139_ENC_3630456  ICD9-D:V67.00   \n",
      "\n",
      "          START_DATE         MODIFIER_CD  VALTYPE_CD  TVAL_CHAR  NVAL_NUM  \\\n",
      "0         2012-04-23                   @         NaN        NaN       NaN   \n",
      "1         2012-07-25                   @         NaN        NaN       NaN   \n",
      "2         2012-11-09                   @         NaN        NaN       NaN   \n",
      "3         2012-03-26                   @         NaN        NaN       NaN   \n",
      "4         2014-05-22                   @         NaN        NaN       NaN   \n",
      "...              ...                 ...         ...        ...       ...   \n",
      "44714088  2014-11-25     DXMOD|SOURCE:PB         NaN        NaN       NaN   \n",
      "44714089  2014-08-01    DXMOD|SOURCE:HIM         NaN        NaN       NaN   \n",
      "44714090  2014-05-08  DXMOD|PRIORITY:SEC         NaN        NaN       NaN   \n",
      "44714091  2014-05-20    DXMOD|SOURCE:HIM         NaN        NaN       NaN   \n",
      "44714092  2014-07-23    DXMOD|PRIORITY:U         NaN        NaN       NaN   \n",
      "\n",
      "          VALUEFLAG_CD  QUANTITY_NUM  UNITS_CD    END_DATE  LOCATION_CD  \\\n",
      "0                  NaN           NaN       NaN  2012-04-23          NaN   \n",
      "1                  NaN           NaN       NaN  2012-07-25          NaN   \n",
      "2                  NaN           NaN       NaN  2012-11-09          NaN   \n",
      "3                  NaN           NaN       NaN  2012-03-26          NaN   \n",
      "4                  NaN           NaN       NaN  2014-05-22          NaN   \n",
      "...                ...           ...       ...         ...          ...   \n",
      "44714088           NaN           NaN       NaN  2014-11-25          NaN   \n",
      "44714089           NaN           NaN       NaN  2014-08-01  502001112.0   \n",
      "44714090           NaN           NaN       NaN  2014-05-08  502001129.0   \n",
      "44714091           NaN           NaN       NaN  2014-05-20  502001112.0   \n",
      "44714092           NaN           NaN       NaN         NaN          NaN   \n",
      "\n",
      "          Class  Field    Value    typ_idx  \n",
      "0           NaN  COMOR  ALCOHOL  Diagnoses  \n",
      "1           NaN  COMOR  ALCOHOL  Diagnoses  \n",
      "2           NaN  COMOR  ALCOHOL  Diagnoses  \n",
      "3           NaN  COMOR  ALCOHOL  Diagnoses  \n",
      "4           NaN  COMOR  ALCOHOL  Diagnoses  \n",
      "...         ...    ...      ...        ...  \n",
      "44714088    NaN   ICD9   366.10  Diagnoses  \n",
      "44714089    NaN   ICD9   338.29  Diagnoses  \n",
      "44714090    NaN   ICD9   278.01  Diagnoses  \n",
      "44714091    NaN   ICD9   278.00  Diagnoses  \n",
      "44714092    NaN   ICD9   V67.00  Diagnoses  \n",
      "\n",
      "[44714093 rows x 17 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(DIAGNOSES.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-basement",
   "metadata": {},
   "source": [
    "## Filter pid missing in either one of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "peripheral-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 1: Merge the dataframes to find common patients\n",
    "merged_df = df_patient_dimension.merge(DIAGNOSES, on='deid_pat_ID', how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "australian-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            deid_pat_ID VITAL_STATUS_CD  BIRTH_DATE DEATH_DATE  SEX_CD  \\\n",
      "0  IRB202001139_PAT_989               N  1931-11-13        NaN    Male   \n",
      "1  IRB202001139_PAT_989               N  1931-11-13        NaN    Male   \n",
      "2  IRB202001139_PAT_730               N  1924-06-24        NaN  Female   \n",
      "3  IRB202001139_PAT_730               N  1924-06-24        NaN  Female   \n",
      "4  IRB202001139_PAT_730               N  1924-06-24        NaN  Female   \n",
      "\n",
      "   AGE_IN_YEARS_NUM LANGUAGE_CD RACE_CD MARITAL_STATUS_CD  RELIGION_CD  ...  \\\n",
      "0                88     English   White            Single          NaN  ...   \n",
      "1                88     English   White            Single          NaN  ...   \n",
      "2                95     English   Other           Married          NaN  ...   \n",
      "3                95     English   Other           Married          NaN  ...   \n",
      "4                95     English   Other           Married          NaN  ...   \n",
      "\n",
      "  NVAL_NUM  VALUEFLAG_CD  QUANTITY_NUM UNITS_CD    END_DATE  LOCATION_CD  \\\n",
      "0      NaN           NaN           NaN      NaN  2013-10-24  302001328.0   \n",
      "1      NaN           NaN           NaN      NaN  2013-10-24  302001328.0   \n",
      "2      NaN           NaN           NaN      NaN  2014-03-04          NaN   \n",
      "3      NaN           NaN           NaN      NaN  2014-03-04          NaN   \n",
      "4      NaN           NaN           NaN      NaN  2012-03-13          NaN   \n",
      "\n",
      "  Class Field   Value    typ_idx  \n",
      "0   NaN  ICD9  331.83  Diagnoses  \n",
      "1   NaN  ICD9  331.83  Diagnoses  \n",
      "2   NaN  ICD9   294.2  Diagnoses  \n",
      "3   NaN  ICD9   294.2  Diagnoses  \n",
      "4   NaN  ICD9   294.2  Diagnoses  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adapted-simon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "academic-background",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-messaging",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "common-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 3: Merge dataframes on 'pid' to get birth_date for each encounter\n",
    "#merged_df = pd.merge(DIAGNOSES, df_patient_dimension[['deid_pat_ID', 'BIRTH_DATE']], on='deid_pat_ID')\n",
    "merged_df['START_DATE'] = pd.to_datetime(merged_df['START_DATE'])\n",
    "merged_df['BIRTH_DATE'] = pd.to_datetime(merged_df['BIRTH_DATE'])\n",
    "merged_df['age_at_encounter'] = (merged_df['START_DATE'] - merged_df['BIRTH_DATE']).dt.days // 365\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "small-idaho",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=54887632, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "rotary-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['deid_pat_ID', 'deid_enc_ID',\"CONCEPT_CD\",'age_at_encounter']\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "merge_df_selected = merged_df[selected_columns]\n",
    "merge_df_selected = merge_df_selected[~merge_df_selected['CONCEPT_CD'].str.startswith('COMOR')]\n",
    "\n",
    "# Assuming you have a DataFrame df with a column named 'ICD Code'\n",
    "# Replace 'ICD Code' with the actual column name if it's different in your DataFrame\n",
    "merge_df_selected['CONCEPT_CD'] = merge_df_selected['CONCEPT_CD'].str.split(':').str[1]\n",
    "\n",
    "# This code splits the string by ':' and selects the second part (index 1), which is the ICD code.\n",
    "\n",
    "# If you want to remove leading or trailing spaces, you can also strip the resulting values:\n",
    "merge_df_selected['CONCEPT_CD'] = merge_df_selected['CONCEPT_CD'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "inside-camel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([       0,        2,        4,        8,       12,       17,       19,\n",
      "             20,       21,       22,\n",
      "       ...\n",
      "       54887609, 54887610, 54887611, 54887612, 54887618, 54887619, 54887620,\n",
      "       54887624, 54887625, 54887630],\n",
      "      dtype='int64', length=13561866)\n",
      "             deid_pat_ID               deid_enc_ID CONCEPT_CD  \\\n",
      "0   IRB202001139_PAT_989    IRB202001139_ENC_38294     331.83   \n",
      "2   IRB202001139_PAT_730    IRB202001139_ENC_38047     294.20   \n",
      "4   IRB202001139_PAT_730    IRB202001139_ENC_40859     294.20   \n",
      "8   IRB202001139_PAT_730    IRB202001139_ENC_38047      298.8   \n",
      "12  IRB202001139_PAT_730    IRB202001139_ENC_38047      458.9   \n",
      "17  IRB202001139_PAT_730    IRB202001139_ENC_19794      692.9   \n",
      "19  IRB202001139_PAT_730  IRB202001139_ENC_1924698      692.9   \n",
      "20  IRB202001139_PAT_730    IRB202001139_ENC_19796      692.9   \n",
      "21  IRB202001139_PAT_730    IRB202001139_ENC_40859      692.9   \n",
      "22  IRB202001139_PAT_730    IRB202001139_ENC_15150      692.9   \n",
      "\n",
      "    age_at_encounter  \n",
      "0                 82  \n",
      "2                 89  \n",
      "4                 87  \n",
      "8                 89  \n",
      "12                89  \n",
      "17                87  \n",
      "19                87  \n",
      "20                87  \n",
      "21                87  \n",
      "22                87  \n"
     ]
    }
   ],
   "source": [
    "merge_df_selected = merge_df_selected.drop_duplicates()\n",
    "print(merge_df_selected.index)\n",
    "print(merge_df_selected.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "defined-dispatch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique deid_pat_ID: 48903\n"
     ]
    }
   ],
   "source": [
    "unique_patients_count = merge_df_selected['deid_pat_ID'].nunique()\n",
    "print(\"Number of unique deid_pat_ID:\", unique_patients_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the mapping code column\n",
    "merge_df_selected['map_code_v3'] = merge_df_selected['CONCEPT_CD'].apply(find_mapped_number_v3)\n",
    "# extract the rows without mapped code\n",
    "df_no_map_code_all = merge_df_selected[merge_df_selected['map_code_v3'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-insertion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_map_code_all.to_csv(\"/data/datasets/leyang.sun/df_no_map_code_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regular-daughter",
   "metadata": {},
   "source": [
    "## Randomly sample 10,000 patients record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "suspected-vermont",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patients = merge_df_selected['deid_pat_ID'].unique()\n",
    "np.random.seed(42)\n",
    "np.random.shuffle(unique_patients)\n",
    "\n",
    "# Sample 10,000 unique patients\n",
    "sampled_patients = unique_patients[:10000]\n",
    "\n",
    "# Create a new DataFrame containing only the sampled patients\n",
    "sampled_df = merge_df_selected[merge_df_selected['deid_pat_ID'].isin(sampled_patients)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "separated-running",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      deid_pat_ID               deid_enc_ID CONCEPT_CD  \\\n",
      "2           IRB202001139_PAT_730    IRB202001139_ENC_38047     294.20   \n",
      "4           IRB202001139_PAT_730    IRB202001139_ENC_40859     294.20   \n",
      "8           IRB202001139_PAT_730    IRB202001139_ENC_38047      298.8   \n",
      "12          IRB202001139_PAT_730    IRB202001139_ENC_38047      458.9   \n",
      "17          IRB202001139_PAT_730    IRB202001139_ENC_19794      692.9   \n",
      "...                          ...                       ...        ...   \n",
      "54887079  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.09XA   \n",
      "54887081  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.59XA   \n",
      "54887086  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.99XA   \n",
      "54887088  IRB202001139_PAT_49106  IRB202001139_ENC_3630503    Z00.129   \n",
      "54887094  IRB202001139_PAT_49106  IRB202001139_ENC_4399182     Z46.82   \n",
      "\n",
      "          age_at_encounter  \n",
      "2                       89  \n",
      "4                       87  \n",
      "8                       89  \n",
      "12                      89  \n",
      "17                      87  \n",
      "...                    ...  \n",
      "54887079                16  \n",
      "54887081                16  \n",
      "54887086                16  \n",
      "54887088                16  \n",
      "54887094                16  \n",
      "\n",
      "[2792146 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(sampled_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "twenty-apparatus",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "adopted-synthesis",
   "metadata": {},
   "outputs": [],
   "source": [
    "def revise_code_to_two_digit(code): # the input code has 2 digits\n",
    "    parts = code.split('.')\n",
    "    if len(parts) > 1:\n",
    "        revised_code = parts[0] + '.' + parts[1][:2]  # Keep the first two digits after the dot\n",
    "        return revised_code\n",
    "    return code\n",
    "\n",
    "def revise_code_to_one_digit(code): # the input code has 2 digits\n",
    "    parts = code.split('.')\n",
    "    if len(parts) > 1:\n",
    "        revised_code = parts[0] + '.' + parts[1][:1]  # Keep the first digit after the dot\n",
    "        return revised_code\n",
    "    return code\n",
    "\n",
    "def revise_code_to_integer(code): # the input code has 1 digit\n",
    "    parts = code.split('.')\n",
    "    if len(parts) > 1:\n",
    "        revised_code = parts[0] # keep the integer part\n",
    "        return revised_code\n",
    "    return code\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "polished-minutes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z87.89\n"
     ]
    }
   ],
   "source": [
    "print(revise_code_to_two_digit(\"Z87.891\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "advanced-firewall",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exact mapping\n",
    "# define the mapping function to perform on a whole dataframe\n",
    "def find_mapped_number_v1(code_to_find):\n",
    "    # try to find the mapped code without revising the code\n",
    "    for disease, mapping in mapping_dict.items():\n",
    "        if code_to_find in mapping['ICD9_1'] or code_to_find in mapping['ICD9_2'] or code_to_find in mapping['ICD10']:\n",
    "            return mapping['MappedNumber']\n",
    "                \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "casual-creativity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the mapping function to perform on a whole dataframe\n",
    "# def find_mapped_number_v3(code_to_find):\n",
    "#     # try to find the mapped code without revising the code\n",
    "#     for disease, mapping in mapping_dict.items():\n",
    "#         if code_to_find in mapping['ICD9_1'] or code_to_find in mapping['ICD9_2'] or code_to_find in mapping['ICD10']:\n",
    "#             return mapping['MappedNumber']\n",
    "    \n",
    "#     # try to revise the code and find the map again\n",
    "#     parts = code_to_find.split('.')\n",
    "#     if len(parts)> 1:\n",
    "#         revised_code = revise_code_to_integer(code_to_find)\n",
    "                        \n",
    "#         for disease, mapping in mapping_dict.items():\n",
    "#             if revised_code in mapping['ICD9_1'] or revised_code in mapping['ICD9_2'] or revised_code in mapping['ICD10']:\n",
    "#                 return mapping['MappedNumber']\n",
    "                \n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "worse-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mapped_number_v3(code_to_find):\n",
    "    # Check if the exact code_to_find exists in the mapping\n",
    "    for disease, mapping in mapping_dict.items():\n",
    "        for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "            for mapped_code in icd_code:\n",
    "                if code_to_find == mapped_code:\n",
    "                    #print(mapped_code)\n",
    "                    return mapping['MappedNumber']\n",
    "               \n",
    "    # If the exact code is not found, try variations 1: code_to_find: 041.12 -> 41.12; 010 -> 10\n",
    "    revised_code_to_find = code_to_find.lstrip('0')\n",
    "    for disease, mapping in mapping_dict.items():\n",
    "        for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "            for mapped_code in icd_code:\n",
    "                if revised_code_to_find == mapped_code:\n",
    "                    #print(mapped_code)\n",
    "                    return mapping['MappedNumber']\n",
    "    \n",
    "    # If the exact code is not found, try variations 2: code_to_find: 10 -> 10.0\n",
    "    revised_code_to_find = revised_code_to_find  + '.0'\n",
    "    for disease, mapping in mapping_dict.items():\n",
    "        for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "            for mapped_code in icd_code:\n",
    "                if revised_code_to_find == mapped_code:\n",
    "                    #print(mapped_code)\n",
    "                    return mapping['MappedNumber']    \n",
    "                \n",
    "    # if both the code variations not found, merge to the major branch \n",
    "    parts = code_to_find.split('.')\n",
    "    if len(parts)> 1:\n",
    "        branch_code = revise_code_to_integer(code_to_find)\n",
    "                        \n",
    "        # retry exact finding\n",
    "        for disease, mapping in mapping_dict.items():\n",
    "            for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "                for mapped_code in icd_code:\n",
    "                    if branch_code == mapped_code:\n",
    "                        #print(mapped_code)\n",
    "                        return mapping['MappedNumber']\n",
    "            \n",
    "            \n",
    "        # retry variations for branch code     \n",
    "        revised_branch_code = branch_code.lstrip('0')\n",
    "        for disease, mapping in mapping_dict.items():\n",
    "            for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "                for mapped_code in icd_code:\n",
    "                    if revised_branch_code == mapped_code:\n",
    "                        #print(mapped_code)\n",
    "                        return mapping['MappedNumber']\n",
    "\n",
    "        # If the exact code is not found, try variations 2: code_to_find: 10 -> 10.0\n",
    "        revised_branch_code = revised_branch_code  + '.0'\n",
    "        for disease, mapping in mapping_dict.items():\n",
    "            for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "                for mapped_code in icd_code:\n",
    "                    if revised_branch_code == mapped_code:\n",
    "                        #print(mapped_code)\n",
    "                        return mapping['MappedNumber']        \n",
    "           \n",
    "                \n",
    "    return None\n",
    "\n",
    "    # Check if the exact code_to_find exists in the mapping\n",
    "    for disease, mapping in mapping_dict.items():\n",
    "        for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "            for mapped_code in icd_code:\n",
    "                if code_to_find == mapped_code:\n",
    "                    #print(mapped_code)\n",
    "                    return mapping['MappedNumber']\n",
    "               \n",
    "    # If the exact code is not found, try variations 1: code_to_find: 041.12 -> 41.12; 010 -> 10\n",
    "    revised_code_to_find = code_to_find.lstrip('0')\n",
    "    for disease, mapping in mapping_dict.items():\n",
    "        for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "            for mapped_code in icd_code:\n",
    "                if revised_code_to_find == mapped_code:\n",
    "                    #print(mapped_code)\n",
    "                    return mapping['MappedNumber']\n",
    "    \n",
    "    # If the exact code is not found, try variations 2: code_to_find: 10 -> 10.0\n",
    "    revised_code_to_find = revised_code_to_find  + '.0'\n",
    "    for disease, mapping in mapping_dict.items():\n",
    "        for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "            for mapped_code in icd_code:\n",
    "                if revised_code_to_find == mapped_code:\n",
    "                   # print(mapped_code)\n",
    "                    return mapping['MappedNumber']    \n",
    "                \n",
    "    # if both the code variations not found, merge to the major branch \n",
    "    parts = code_to_find.split('.')\n",
    "    if len(parts)> 1:\n",
    "        branch_code = revise_code_to_integer(code_to_find)\n",
    "                        \n",
    "        # retry exact finding\n",
    "        for disease, mapping in mapping_dict.items():\n",
    "            for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "                for mapped_code in icd_code:\n",
    "                    if branch_code == mapped_code:\n",
    "                       # print(mapped_code)\n",
    "                        return mapping['MappedNumber']\n",
    "            \n",
    "            \n",
    "        # retry variations for branch code     \n",
    "        revised_branch_code = branch_code.lstrip('0')\n",
    "        for disease, mapping in mapping_dict.items():\n",
    "            for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "                for mapped_code in icd_code:\n",
    "                    if revised_branch_code == mapped_code:\n",
    "                       # print(mapped_code)\n",
    "                        return mapping['MappedNumber']\n",
    "\n",
    "        # If the exact code is not found, try variations 2: code_to_find: 10 -> 10.0\n",
    "        revised_branch_code = revised_branch_code  + '.0'\n",
    "        for disease, mapping in mapping_dict.items():\n",
    "            for icd_code in [mapping['ICD9_1'], mapping['ICD9_2'], mapping['ICD10']]:\n",
    "                for mapped_code in icd_code:\n",
    "                    if revised_branch_code == mapped_code:\n",
    "                        #print(mapped_code)\n",
    "                        return mapping['MappedNumber']        \n",
    "           \n",
    "                \n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "prepared-mounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code = 'R11.20'\n",
    "# parts = code.split('.')\n",
    "# print(len(parts))\n",
    "# print(len(parts[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "characteristic-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # define the mapping function to perform on a whole dataframe\n",
    "# def find_mapped_number_v2(code_to_find):\n",
    "#     # try to find the mapped code without revising the code\n",
    "#     for disease, mapping in mapping_dict.items():\n",
    "#         if code_to_find in mapping['ICD9_1'] or code_to_find in mapping['ICD9_2'] or code_to_find in mapping['ICD10']:\n",
    "#             return mapping['MappedNumber']\n",
    "    \n",
    "#     # try to revise the code and find the map again\n",
    "#     parts = code_to_find.split('.')\n",
    "#     if len(parts) > 1:\n",
    "#         if len(parts[1]) > 1: # in the format of \"'R11.20'\"\n",
    "#             revised_code = revise_code_to_one_digit(code_to_find)\n",
    "#             for disease, mapping in mapping_dict.items():\n",
    "#                 if revised_code in mapping['ICD9_1'] or revised_code in mapping['ICD9_2'] or revised_code in mapping['ICD10']:\n",
    "#                     return mapping['MappedNumber']\n",
    "#                 else:\n",
    "#                     revised_code = revise_code_to_integer(revised_code) # in the format of \"'R11.2'\"\n",
    "#                     for disease, mapping in mapping_dict.items():\n",
    "#                         if revised_code in mapping['ICD9_1'] or revised_code in mapping['ICD9_2'] or revised_code in mapping['ICD10']:\n",
    "#                             return mapping['MappedNumber']\n",
    "                        \n",
    "#         elif len(parts[1]) == 1: # in the format of \"'R11.2'\"\n",
    "#             revised_code = revise_code_to_integer(code_to_find)\n",
    "#             for disease, mapping in mapping_dict.items():\n",
    "#                 if revised_code in mapping['ICD9_1'] or revised_code in mapping['ICD9_2'] or revised_code in mapping['ICD10']:\n",
    "#                     return mapping['MappedNumber']\n",
    "                \n",
    "#     return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "convertible-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = sampled_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "commercial-millennium",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95315/1555334246.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sampled_df['map_code_v3'] = sampled_df['CONCEPT_CD'].apply(find_mapped_number_v3)\n"
     ]
    }
   ],
   "source": [
    "# add the mapping code column\n",
    "sampled_df['map_code_v3'] = sampled_df['CONCEPT_CD'].apply(find_mapped_number_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "caring-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      deid_pat_ID               deid_enc_ID CONCEPT_CD  \\\n",
      "2           IRB202001139_PAT_730    IRB202001139_ENC_38047     294.20   \n",
      "4           IRB202001139_PAT_730    IRB202001139_ENC_40859     294.20   \n",
      "8           IRB202001139_PAT_730    IRB202001139_ENC_38047      298.8   \n",
      "12          IRB202001139_PAT_730    IRB202001139_ENC_38047      458.9   \n",
      "17          IRB202001139_PAT_730    IRB202001139_ENC_19794      692.9   \n",
      "...                          ...                       ...        ...   \n",
      "54887079  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.09XA   \n",
      "54887081  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.59XA   \n",
      "54887086  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.99XA   \n",
      "54887088  IRB202001139_PAT_49106  IRB202001139_ENC_3630503    Z00.129   \n",
      "54887094  IRB202001139_PAT_49106  IRB202001139_ENC_4399182     Z46.82   \n",
      "\n",
      "          age_at_encounter  map_code_v3  \n",
      "2                       89          NaN  \n",
      "4                       87          NaN  \n",
      "8                       89          NaN  \n",
      "12                      89        914.0  \n",
      "17                      87          NaN  \n",
      "...                    ...          ...  \n",
      "54887079                16          NaN  \n",
      "54887081                16          NaN  \n",
      "54887086                16          NaN  \n",
      "54887088                16          NaN  \n",
      "54887094                16          NaN  \n",
      "\n",
      "[2792146 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(sampled_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "rural-scottish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the rows without mapped code\n",
    "df_no_map_code = sampled_df[sampled_df['map_code_v3'].isna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "medium-occurrence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([       2,        4,        8,       17,       19,       20,       21,\n",
      "             22,     1328,     1330,\n",
      "       ...\n",
      "       54883942, 54883949, 54883951, 54883952, 54883955, 54887079, 54887081,\n",
      "       54887086, 54887088, 54887094],\n",
      "      dtype='int64', length=647738)\n"
     ]
    }
   ],
   "source": [
    "print(df_no_map_code.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "sapphire-gauge",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_map_code.to_csv(\"/data/datasets/leyang.sun/df_no_map_code.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "acute-arctic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                      deid_pat_ID               deid_enc_ID CONCEPT_CD  \\\n",
      "2           IRB202001139_PAT_730    IRB202001139_ENC_38047     294.20   \n",
      "4           IRB202001139_PAT_730    IRB202001139_ENC_40859     294.20   \n",
      "8           IRB202001139_PAT_730    IRB202001139_ENC_38047      298.8   \n",
      "17          IRB202001139_PAT_730    IRB202001139_ENC_19794      692.9   \n",
      "19          IRB202001139_PAT_730  IRB202001139_ENC_1924698      692.9   \n",
      "...                          ...                       ...        ...   \n",
      "54887079  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.09XA   \n",
      "54887081  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.59XA   \n",
      "54887086  IRB202001139_PAT_49106  IRB202001139_ENC_3630503   V86.99XA   \n",
      "54887088  IRB202001139_PAT_49106  IRB202001139_ENC_3630503    Z00.129   \n",
      "54887094  IRB202001139_PAT_49106  IRB202001139_ENC_4399182     Z46.82   \n",
      "\n",
      "          age_at_encounter  map_code_v3  \n",
      "2                       89          NaN  \n",
      "4                       87          NaN  \n",
      "8                       89          NaN  \n",
      "17                      87          NaN  \n",
      "19                      87          NaN  \n",
      "...                    ...          ...  \n",
      "54887079                16          NaN  \n",
      "54887081                16          NaN  \n",
      "54887086                16          NaN  \n",
      "54887088                16          NaN  \n",
      "54887094                16          NaN  \n",
      "\n",
      "[647738 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df_no_map_code.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "negative-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with NaN in codemap\n",
    "merge_df_selected_dropna = sampled_df.dropna(subset=['map_code_v3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "common-baking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([      12,       28,       29,       32,       34,       37,       42,\n",
      "             44,      760,      761,\n",
      "       ...\n",
      "       54887044, 54887046, 54887049, 54887051, 54887054, 54887056, 54887065,\n",
      "       54887073, 54887075, 54887077],\n",
      "      dtype='int64', length=2144408)\n",
      "              deid_pat_ID             deid_enc_ID CONCEPT_CD  \\\n",
      "12   IRB202001139_PAT_730  IRB202001139_ENC_38047      458.9   \n",
      "28   IRB202001139_PAT_730  IRB202001139_ENC_40859     695.89   \n",
      "29   IRB202001139_PAT_730  IRB202001139_ENC_19796     695.89   \n",
      "32   IRB202001139_PAT_730  IRB202001139_ENC_15150      695.9   \n",
      "34   IRB202001139_PAT_730  IRB202001139_ENC_15150      709.9   \n",
      "37   IRB202001139_PAT_730  IRB202001139_ENC_38047     780.79   \n",
      "42   IRB202001139_PAT_730  IRB202001139_ENC_25578      782.1   \n",
      "44   IRB202001139_PAT_730  IRB202001139_ENC_15150      782.1   \n",
      "760  IRB202001139_PAT_679   IRB202001139_ENC_8973      E04.9   \n",
      "761  IRB202001139_PAT_679  IRB202001139_ENC_40194      E04.9   \n",
      "\n",
      "     age_at_encounter  map_code_v3  \n",
      "12                 89        914.0  \n",
      "28                 87       1428.0  \n",
      "29                 87       1428.0  \n",
      "32                 87       1440.0  \n",
      "34                 87       1482.0  \n",
      "37                 89       1696.0  \n",
      "42                 87       1700.0  \n",
      "44                 87       1700.0  \n",
      "760                54       1920.0  \n",
      "761                54       1920.0  \n"
     ]
    }
   ],
   "source": [
    "print(merge_df_selected_dropna.index)\n",
    "print(merge_df_selected_dropna.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "virtual-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sort within each patient group by 'age_at_encounter'\n",
    "merge_df_selected_dropna_sorted = merge_df_selected_dropna.sort_values(by=['deid_pat_ID', 'age_at_encounter'])\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "# print(merge_df_selected_sorted.head(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "exempt-integration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  107652,   107658,   107671,   107675,   107688,   107689,   107692,\n",
      "         107695,   107700,   107716,\n",
      "       ...\n",
      "       47278244, 47278246, 47278247, 47278252, 47278253, 47278254, 47278255,\n",
      "       47278256, 47278257, 47278267],\n",
      "      dtype='int64', length=2144408)\n"
     ]
    }
   ],
   "source": [
    "print(merge_df_selected_dropna_sorted.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "applied-university",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([  107652,   107658,   107688,   107689,   107718,   107731,   107425,\n",
      "         107410,   107448,   107450,\n",
      "       ...\n",
      "       47278186, 47278194, 47278211, 47278246, 47278247, 47278252, 47278253,\n",
      "       47278255, 47278256, 47278257],\n",
      "      dtype='int64', length=493693)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Remove duplicate encounters to prepare for age column for each patient, the df for age extraction is merge_df_age\n",
    "merge_df_age = merge_df_selected_dropna_sorted.drop_duplicates(subset=['deid_pat_ID', 'deid_enc_ID'])\n",
    "print(merge_df_age.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "refined-dictionary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                  deid_pat_ID  \\\n",
      "0         IRB202001139_PAT_1   \n",
      "1        IRB202001139_PAT_10   \n",
      "2     IRB202001139_PAT_10001   \n",
      "3     IRB202001139_PAT_10002   \n",
      "4     IRB202001139_PAT_10009   \n",
      "...                      ...   \n",
      "9916   IRB202001139_PAT_9958   \n",
      "9917   IRB202001139_PAT_9965   \n",
      "9918   IRB202001139_PAT_9977   \n",
      "9919   IRB202001139_PAT_9992   \n",
      "9920   IRB202001139_PAT_9993   \n",
      "\n",
      "                                             age_vector  \n",
      "0     [31, 31, 31, 31, 31, 31, 32, 33, 33, 33, 33, 3...  \n",
      "1     [69, 69, 70, 70, 70, 70, 70, 70, 71, 71, 71, 7...  \n",
      "2     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3     [19, 19, 20, 20, 21, 21, 21, 22, 22, 22, 22, 2...  \n",
      "4     [66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 6...  \n",
      "...                                                 ...  \n",
      "9916                               [62, 62, 62, 62, 62]  \n",
      "9917  [77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 77, 7...  \n",
      "9918  [9, 11, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12...  \n",
      "9919                                               [59]  \n",
      "9920  [86, 86, 86, 86, 86, 87, 87, 87, 87, 87, 87, 8...  \n",
      "\n",
      "[9921 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "# get age_vector for each patient\n",
    "\n",
    "# Group by 'pid' and aggregate 'age_at_encounter' into a list\n",
    "patient_age_df = merge_df_age.groupby('deid_pat_ID')['age_at_encounter'].agg(list).reset_index()\n",
    "\n",
    "# Rename the column to 'age_vector'\n",
    "patient_age_df = patient_age_df.rename(columns={'age_at_encounter': 'age_vector'})\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(patient_age_df.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-morocco",
   "metadata": {},
   "source": [
    "## 3. Aggregate the diagnosis codes of the patients under the same encounter defined by deid_enc_ID under DIAGNOSIS.csv. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "advisory-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                     deid_pat_ID               deid_enc_ID CONCEPT_CD  \\\n",
      "107652       IRB202001139_PAT_1    IRB202001139_ENC_31294      276.2   \n",
      "107658       IRB202001139_PAT_1  IRB202001139_ENC_1925177      276.2   \n",
      "107671       IRB202001139_PAT_1    IRB202001139_ENC_31294     276.69   \n",
      "107675       IRB202001139_PAT_1    IRB202001139_ENC_31294      285.9   \n",
      "107688       IRB202001139_PAT_1  IRB202001139_ENC_1923892      344.9   \n",
      "...                         ...                       ...        ...   \n",
      "47278254  IRB202001139_PAT_9993  IRB202001139_ENC_3795741     793.19   \n",
      "47278255  IRB202001139_PAT_9993  IRB202001139_ENC_3795722     793.19   \n",
      "47278256  IRB202001139_PAT_9993  IRB202001139_ENC_3795724     793.19   \n",
      "47278257  IRB202001139_PAT_9993  IRB202001139_ENC_3795687     793.19   \n",
      "47278267  IRB202001139_PAT_9993  IRB202001139_ENC_2914116     794.31   \n",
      "\n",
      "          age_at_encounter  map_code_v3  \n",
      "107652                  31        366.0  \n",
      "107658                  31        366.0  \n",
      "107671                  31        366.0  \n",
      "107675                  31        418.0  \n",
      "107688                  31        579.0  \n",
      "...                    ...          ...  \n",
      "47278254                87       1717.0  \n",
      "47278255                87       1717.0  \n",
      "47278256                87       1717.0  \n",
      "47278257                87       1717.0  \n",
      "47278267                87       1719.0  \n",
      "\n",
      "[2144408 rows x 5 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(merge_df_selected_dropna_sorted.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "published-tuesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_selected_columns = ['deid_pat_ID', 'deid_enc_ID',\"map_code_v3\"]\n",
    "\n",
    "\n",
    "# Create a new DataFrame with the selected columns\n",
    "merge_df_diagnosis = merge_df_selected_dropna_sorted[diagnosis_selected_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "daily-humanity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                    deid_pat_ID               deid_enc_ID  map_code_v3\n",
      "0           IRB202001139_PAT_1    IRB202001139_ENC_31294        366.0\n",
      "1           IRB202001139_PAT_1  IRB202001139_ENC_1925177        366.0\n",
      "2           IRB202001139_PAT_1    IRB202001139_ENC_31294        366.0\n",
      "3           IRB202001139_PAT_1    IRB202001139_ENC_31294        418.0\n",
      "4           IRB202001139_PAT_1  IRB202001139_ENC_1923892        579.0\n",
      "...                        ...                       ...          ...\n",
      "2144403  IRB202001139_PAT_9993  IRB202001139_ENC_3795741       1717.0\n",
      "2144404  IRB202001139_PAT_9993  IRB202001139_ENC_3795722       1717.0\n",
      "2144405  IRB202001139_PAT_9993  IRB202001139_ENC_3795724       1717.0\n",
      "2144406  IRB202001139_PAT_9993  IRB202001139_ENC_3795687       1717.0\n",
      "2144407  IRB202001139_PAT_9993  IRB202001139_ENC_2914116       1719.0\n",
      "\n",
      "[2144408 rows x 3 columns]>\n"
     ]
    }
   ],
   "source": [
    "merge_df_diagnosis = merge_df_diagnosis.reset_index(drop=True)\n",
    "print(merge_df_diagnosis.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "computational-circular",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of                          pid  \\\n",
      "0         IRB202001139_PAT_1   \n",
      "1        IRB202001139_PAT_10   \n",
      "2     IRB202001139_PAT_10001   \n",
      "3     IRB202001139_PAT_10002   \n",
      "4     IRB202001139_PAT_10009   \n",
      "...                      ...   \n",
      "9916   IRB202001139_PAT_9958   \n",
      "9917   IRB202001139_PAT_9965   \n",
      "9918   IRB202001139_PAT_9977   \n",
      "9919   IRB202001139_PAT_9992   \n",
      "9920   IRB202001139_PAT_9993   \n",
      "\n",
      "                                                   code  \n",
      "0     [CLS, 366.0, 366.0, 418.0, 705.0, 760.0, 838.0...  \n",
      "1     [CLS, 1117.0, 1113.0, 65.0, 72.0, 366.0, 366.0...  \n",
      "2     [CLS, 35.0, 920.0, 1696.0, SEP, 388.0, SEP, 43...  \n",
      "3     [CLS, 492.0, 1531.0, 1534.0, SEP, 1707.0, SEP,...  \n",
      "4     [CLS, 250.0, 579.0, 590.0, 590.0, 760.0, 824.0...  \n",
      "...                                                 ...  \n",
      "9916  [CLS, 159.0, 162.0, 164.0, 315.0, 479.0, 492.0...  \n",
      "9917  [CLS, 119.0, 159.0, 162.0, 164.0, 172.0, SEP, ...  \n",
      "9918  [CLS, 1.0, 1.0, 366.0, 392.0, 392.0, 498.0, 17...  \n",
      "9919  [CLS, 10.0, 71.0, 315.0, 352.0, 352.0, 366.0, ...  \n",
      "9920  [CLS, 345.0, 760.0, 775.0, 813.0, 813.0, 830.0...  \n",
      "\n",
      "[9921 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store aggregated vectors\n",
    "pid_diagnosis_dict = {}\n",
    "\n",
    "# Iterate through each row of the DataFrame\n",
    "for index, row in merge_df_diagnosis.iterrows():\n",
    "    pid = row['deid_pat_ID']\n",
    "    encounter_id = row['deid_enc_ID']\n",
    "    code = row['map_code_v3']\n",
    "\n",
    "    # Check if the pid is already in the dictionary\n",
    "    if pid in pid_diagnosis_dict:\n",
    "        # Check if encounter_id is already in the dictionary\n",
    "        if encounter_id in pid_diagnosis_dict[pid]:\n",
    "            # Append the diagnosis code to the existing encounter_id vector\n",
    "            pid_diagnosis_dict[pid][encounter_id].append(code)\n",
    "        else:\n",
    "            # Initialize a new encounter_id vector if encounter_id is not in the dictionary\n",
    "            pid_diagnosis_dict[pid][encounter_id] = [code]\n",
    "    else:\n",
    "        # Initialize a new dictionary entry for pid and encounter_id\n",
    "        pid_diagnosis_dict[pid] = {encounter_id: [code]}\n",
    "\n",
    "# Initialize an empty list to store the final rows of the new DataFrame\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through the dictionary to create rows for the new DataFrame\n",
    "for pid, encounters in pid_diagnosis_dict.items():\n",
    "    # Concatenate the vectors for each encounter_id\n",
    "    concatenated_codes = []\n",
    "    for encounter_id, codes in encounters.items():\n",
    "        concatenated_codes += codes + ['SEP']\n",
    "\n",
    "    # Create a new row with pid, encounter_id, and the aggregated code vector\n",
    "    new_row = {'pid': pid, 'code': ['CLS'] + concatenated_codes}\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Create the new DataFrame\n",
    "patient_code_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(patient_code_df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "seventh-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(patient_code_df.columns)\n",
    "column_mapping = {\n",
    "    'pid': 'deid_pat_ID',\n",
    "    'code': 'diagnosis_code'\n",
    "}\n",
    "\n",
    "patient_code_df = patient_code_df.rename(columns=column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "necessary-graphics",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df = patient_age_df.merge(patient_code_df, on='deid_pat_ID')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "twelve-alexandria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               deid_pat_ID                                         age_vector  \\\n",
      "0       IRB202001139_PAT_1  [31, 31, 31, 31, 31, 31, 32, 33, 33, 33, 33, 3...   \n",
      "1      IRB202001139_PAT_10  [69, 69, 70, 70, 70, 70, 70, 70, 71, 71, 71, 7...   \n",
      "2   IRB202001139_PAT_10001  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3   IRB202001139_PAT_10002  [19, 19, 20, 20, 21, 21, 21, 22, 22, 22, 22, 2...   \n",
      "4   IRB202001139_PAT_10009  [66, 66, 66, 66, 67, 67, 67, 67, 67, 67, 67, 6...   \n",
      "5   IRB202001139_PAT_10011                                               [80]   \n",
      "6   IRB202001139_PAT_10014                                   [64, 65, 68, 68]   \n",
      "7   IRB202001139_PAT_10018  [58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 58, 5...   \n",
      "8   IRB202001139_PAT_10020                   [83, 83, 83, 83, 83, 84, 84, 84]   \n",
      "9   IRB202001139_PAT_10025  [48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 48, 4...   \n",
      "10  IRB202001139_PAT_10034  [48, 48, 49, 49, 49, 49, 49, 49, 49, 50, 50, 5...   \n",
      "11  IRB202001139_PAT_10037                                   [46, 46, 46, 46]   \n",
      "12  IRB202001139_PAT_10039  [21, 23, 23, 23, 23, 23, 23, 23, 23, 23, 23, 2...   \n",
      "13   IRB202001139_PAT_1004  [30, 32, 32, 32, 32, 32, 32, 32, 33, 34, 34, 3...   \n",
      "14  IRB202001139_PAT_10040  [77, 77, 77, 77, 77, 77, 77, 78, 78, 78, 78, 7...   \n",
      "15  IRB202001139_PAT_10041  [59, 59, 59, 59, 60, 60, 60, 60, 60, 60, 60, 6...   \n",
      "16  IRB202001139_PAT_10046  [62, 62, 62, 62, 62, 62, 62, 63, 63, 63, 63, 6...   \n",
      "17  IRB202001139_PAT_10047                                   [45, 45, 45, 45]   \n",
      "18  IRB202001139_PAT_10048  [81, 81, 81, 81, 82, 82, 82, 82, 82, 82, 82, 8...   \n",
      "19  IRB202001139_PAT_10054       [69, 69, 69, 69, 69, 69, 69, 69, 69, 69, 69]   \n",
      "\n",
      "                                       diagnosis_code  \n",
      "0   [CLS, 366.0, 366.0, 418.0, 705.0, 760.0, 838.0...  \n",
      "1   [CLS, 1117.0, 1113.0, 65.0, 72.0, 366.0, 366.0...  \n",
      "2   [CLS, 35.0, 920.0, 1696.0, SEP, 388.0, SEP, 43...  \n",
      "3   [CLS, 492.0, 1531.0, 1534.0, SEP, 1707.0, SEP,...  \n",
      "4   [CLS, 250.0, 579.0, 590.0, 590.0, 760.0, 824.0...  \n",
      "5   [CLS, 345.0, 366.0, 553.0, 760.0, 807.0, 829.0...  \n",
      "6   [CLS, 1532.0, 1696.0, 1696.0, SEP, 760.0, 1717...  \n",
      "7   [CLS, 570.0, SEP, 570.0, SEP, 760.0, 1506.0, 1...  \n",
      "8   [CLS, 236.0, 760.0, 1564.0, 1696.0, SEP, 418.0...  \n",
      "9   [CLS, 345.0, 499.0, 760.0, 775.0, 775.0, 814.0...  \n",
      "10  [CLS, 345.0, 398.0, 761.0, 1696.0, SEP, 663.0,...  \n",
      "11  [CLS, 540.0, 760.0, 840.0, 844.0, 865.0, 865.0...  \n",
      "12  [CLS, 1720.0, 1720.0, SEP, 71.0, 1038.0, 1117....  \n",
      "13  [CLS, 936.0, 1271.0, 1320.0, 1696.0, 71.0, 126...  \n",
      "14  [CLS, 653.0, 760.0, 1145.0, 1158.0, 1204.0, 15...  \n",
      "15  [CLS, 1902.0, 1902.0, 1920.0, 1920.0, 345.0, 3...  \n",
      "16  [CLS, 126.0, 126.0, SEP, 126.0, 741.0, SEP, 12...  \n",
      "17  [CLS, 176.0, 250.0, 570.0, 829.0, 1753.0, 1753...  \n",
      "18  [CLS, 557.0, SEP, 557.0, SEP, 557.0, SEP, 557....  \n",
      "19  [CLS, 328.0, 366.0, 366.0, 415.0, 492.0, 502.0...  \n"
     ]
    }
   ],
   "source": [
    "print(final_merged_df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "front-native",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merged_df.to_csv(\"/data/datasets/leyang.sun/merged_age_diagnosis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-explorer",
   "metadata": {},
   "source": [
    "## Create Vocabulary for Age Codes (age2idx) and Diagnosis Codes (diagnosis2idx):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abandoned-score",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Example DataFrame\n",
    "data = {'pid': [1, 1, 1, 2, 2],\n",
    "        'encounter_id': [101, 101, 102, 201, 202],\n",
    "        'diagnosis_code': ['1', '2', '3', '4', '5']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Initialize an empty dictionary to store aggregated vectors\n",
    "pid_diagnosis_dict = {}\n",
    "\n",
    "# Iterate through each row of the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    pid = row['pid']\n",
    "    encounter_id = row['encounter_id']\n",
    "    code = row['diagnosis_code']\n",
    "\n",
    "    # Check if the pid is already in the dictionary\n",
    "    if pid in pid_diagnosis_dict:\n",
    "        # Check if encounter_id is already in the dictionary\n",
    "        if encounter_id in pid_diagnosis_dict[pid]:\n",
    "            # Append the diagnosis code to the existing encounter_id vector\n",
    "            pid_diagnosis_dict[pid][encounter_id].append(code)\n",
    "        else:\n",
    "            # Initialize a new encounter_id vector if encounter_id is not in the dictionary\n",
    "            pid_diagnosis_dict[pid][encounter_id] = [code]\n",
    "    else:\n",
    "        # Initialize a new dictionary entry for pid and encounter_id\n",
    "        pid_diagnosis_dict[pid] = {encounter_id: [code]}\n",
    "\n",
    "# Initialize an empty list to store the final rows of the new DataFrame\n",
    "new_rows = []\n",
    "\n",
    "# Iterate through the dictionary to create rows for the new DataFrame\n",
    "for pid, encounters in pid_diagnosis_dict.items():\n",
    "    # Concatenate the vectors for each encounter_id\n",
    "    concatenated_codes = []\n",
    "    for encounter_id, codes in encounters.items():\n",
    "        concatenated_codes += codes + ['SEP']\n",
    "\n",
    "    # Create a new row with pid, encounter_id, and the aggregated code vector\n",
    "    new_row = {'pid': pid, 'code': ['CLS'] + concatenated_codes}\n",
    "    new_rows.append(new_row)\n",
    "\n",
    "# Create the new DataFrame\n",
    "patient_code_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Print the new DataFrame\n",
    "print(patient_code_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-equity",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python-leyang.sun",
   "language": "python",
   "name": "leyang.sun-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
